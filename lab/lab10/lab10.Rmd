---
title: 'Lab 10: Proportions and Inference'
author: 'Your name and Student ID'
date: "Today's date"
output: pdf_document
---


### Instructions 
* Due date: Friday, August 13 at 10:00pm PST with 2 hour grace period.
* Late penalty: 50% late penalty if submitted within 24 hours of due date, no 
marks for assignments submitted thereafter.
* This assignment is graded on **correct completion**, all or nothing. You must pass all public tests and submit the assignment for credit.
* Submission process: Follow the submission instructions on the final page. Make sure you do not remove any `\newpage` tags or rename this file, as this will break the submission.


### Boston Data on Median Household Value and Distance to Employment Centers

We are examining a data set used to predict housing prices in the area around Boston (Harrison, D. and Rubinfeld, 1978).  We wish to examine specifically the association of the measure of housing price (`medv`, median value of owner-occupied homes in the $1000s) and a measure of adjacency to employment (a weighted distance, roughly in miles).  The data frame (Boston) is contained in another package (MASS), which we load below.

```{r, message=F}
### NOTE: All of the code is to get you started on the lab. You do not need to
### understand any functions below that you have not seen before.

# Load library with data
library(MASS)

### NOTE: This package has a function `select()` that can be confused with
### dplyr's select. To overcome this, we first import the data we need and then
### detach the library before loading dplyr.

# List variables
boston_housing <- 
  read.csv("data/Boston.csv")

# Variable definition - take a quick look at the variables in the data frame
#help(Boston)
detach(package:MASS)
library(broom)
library(dplyr)
library(ggplot2)
library(tidyr)
library(patchwork)

### Normally, when we are doing inference, we take a random sample from the  
### entire population so we can see how well we can make inference when we only 
### have 50 rows of data. If you have after the lab, try taking the following  
### random sample from the data, and see if your results change.
```

\newpage

## Section 1

1. [1 mark] Perform and summarize the results of a linear regression of `medv` (median value of owner-occupied homes in \$1000s) and  `dis` (weighted mean of distances to five Boston employment centres) using Boston data. 

Assign the linear model to an object called `p1`.

Be careful about which variable is explanatory and which is response! 

```{r p1}
p1 <- NULL # YOUR CODE HERE
```

```{r}
. = ottr::check("tests/p1.R")
```


\newpage

2. [1 mark] Interpret the slope parameter and p-value from the table. What null and alternative hypotheses does this p-value refer to?  Store the slope parameter, ROUNDED to 2 decimal places, to the object `p2`.

```{r p2}
p2 <- "YOUR ANSWER HERE"

# YOUR CODE HERE
```

```{r}
. = ottr::check("tests/p2.R")
```
_Type your answer here, replacing this text._

\newpage

3. [1 mark] Derive a 95\% CI for this slope parameter and assign the object `p8` to a vector of the lower bound followed by the upper bound of the interval, to AT LEAST one decimal place of precision. In your opinion, would you expect the direction of this relationship to hold if the data were collected today?

```{r p3}
#Put your code here
p3 <- "YOUR ANSWER HERE"

```

_Type your answer here, replacing this text._


\newpage

4. [1 mark] Use a function to look at the r-squared value for this model. Assign the r-squared ROUNDED to 2 decimal places, to the object `p4`. Does `dis` explain alot of the variance in median household value? Would you expect it to? 

```{r p4}
p4 <- "YOUR ANSWER HERE"

```

```{r}
. = ottr::check("tests/p4.R")
```
_Type your answer here, replacing this text._


\newpage

5. [2 marks] Back to the fit of the model of `medv` vs. `dis`.  Make a plot with the raw data points, the fitted line from the simple linear regression model (only containing `medv` and `dis`) and also add a line with a slope of 0. You can have that line cross the y axis at the average value of `medv` to vertically bisect the data points. Store your plot as the object `p5`.

```{r p5, echo=F, fig.align='center', out.width="80%"}
p5 <- "CODE YOUR PLOT HERE"

```

```{r}
. = ottr::check("tests/p5.R")
```

\newpage

6. [2 marks] For you, does the plot raise any concerns about the assumptions of the linear regression you just performed?  What other plots might you do to explore the fit? One helpful plot would compare the distribution of model residuals to a theoretical normal distribution.  Assign the object `p6` to the FIRST TWO LETTERS of the name of this plot.
## STOP: REMOVE EVAL= F FROM THIS CODE CHUNK BEFORE CONTINUING ON
```{r p6, eval = F}
p6 <- "YOUR ANSWER HERE"

# YOUR CODE HERE

## Go over this code with your GSI and make sure you understand it.


### below are some plots for model diagnostics that we've gone over in lecture.
data_with_predictions <-
  augment(p1)
ggplot(data_with_predictions, aes(dis, medv)) +
  geom_smooth(method = "lm", se = F) +
  geom_point(alpha = 0.5) +
  geom_segment(aes(xend = dis, yend = .fitted), lty = 2, alpha = 0.5) +
  theme_minimal(base_size = 15) +
  labs(title = "(a) Scatter plot")
ggplot(data_with_predictions, aes(sample = .resid)) +
  geom_qq() +
  geom_qq_line() +
  theme_minimal(base_size = 15) +
  labs(y = "Residuals", x = "Theoretical quantiles", title = "(b) QQplot")
ggplot(data_with_predictions, aes(y = .resid, x = .fitted)) +
  geom_point() +
  theme_minimal(base_size = 15) +
  geom_hline(aes(yintercept = 0)) +
  labs(y = "Residuals", x = "Fitted values", title = "(c) Fitted vs. residuals")
predictions_reshaped <- 
  data_with_predictions %>% 
  select(medv, .resid) %>%
  gather(key = "type", value = "value", medv, .resid)
ggplot(predictions_reshaped, aes(y = value)) +
  geom_boxplot(aes(fill = type)) +
  theme_minimal(base_size = 15) +
  labs(title = "(d) Amount explained")
```

```{r}
. = ottr::check("tests/p6.R")
```
_Type your answer here, replacing this text._

\vspace{20pt}

Regardless of your answer, we go forward using the model to make inferences about the points on the line.

\newpage

### Pointwise Confidence Intervals and Multiple Testing

As you learned in lecture, there are two types of confidence intervals applicable to estimating a point on the plot which are related to whether one is predicting the population average among individuals with $X=x$ (**mean response**) or whether one is predicting the actual $Y$ for a particular individual (** single observation**). For this assignment, we will concentrate on the confidence interval for the mean response.  We do so because it is rare to use statistical models in public health as forecasting models (predicting an individual's health in the future) and more common to use them to estimate population-level changes (how does the mean health change in a population as we change exposure).  However, as precision medicine becomes more of a reality and the models accurately predict health (i.e., have high $R^2$'s), then statistical forecasting may become more common in our field.

7. [2 marks] Calculate four 95\% confidence intervals for the mean response, one at each `dis` value: 2.5, 5.0, 7.5, and 10.0 miles. Store the lower bounds for each confidence interval, ROUNDED to two decimal places, in a vector called `p7`.

**Hint: Use the predict function, and be sure to specify interval = "confidence"**

OPTIONAL: If time allows, add the four CIs to a scatter plot of the data (along with the line of best fit).

```{r p7}
#Put your code here
### Helpful Data Frame:
ci_dataframe <-
  data.frame(dis = c(2.5, 5.0, 7.5, 10))
p7 <- "YOUR CODE AND ANSWER HERE"

```

```{r}
. = ottr::check("tests/p7.R")
```

\newpage

8. [1 mark] Interpret the pointwise 95\% confidence interval of the median house price when distance = 10. 

_Type your answer here, replacing this text._


\newpage

9. [1 mark] Do the CI's differ in length for different values of `dis`?  Why or why not?

_Type your answer here, replacing this text._

\newpage

## Section 2

**The rest of the assignment is for practice. You are responsible for the material but it will not be part of your grade.**

### Tests of Changes in Sex Ratios Based on a Single Sample

There is a long literature studying changes in sex-ratios of births due to stressful events, such as 9/11. In today's lab, we consider a relatively small study that recorded biomarkers of stress on pregnancy.  In the group of subjects that had the highest markers of stress (based on cortisol), there were 14 births to males out of a total of 38.

In this lab, we will compare the four methods we learned to calculate CIs for proportions. Recall that two of these methods involved hand calculations (though we can treat R as if it were a calculator) and two of the methods used built-in R functions.

Store your answers to questions that ask for confidence intervals like so:

```{r eval = F}
pX <- c(lowerbound, upperbound)

# For example, if lowerbound = 10, upperbound = 20:
pX <- c(10, 20)
```

10. [1 mark] Use the Normal approximation to construct a 95% (using z = 1.96) confidence interval in this high stress group. Store your answer to `p10` using the following format: `p10 <- c(lowerbound, upperbound)`. We also call this specific method of constructing the CI the "large sample method".

```{r large-sample-method}
# YOUR CODE HERE

# Replace "lowerbound" and "upperbound" with your answer
# If your answer is a number, make sure it doesn't have quotes around it
p10 <- c("lowerbound", "upperbound")
p10

# YOUR CODE HERE
```

```{r}
. = ottr::check("tests/p10.R")
```

\newpage

11. [1 mark] Create the 95% CI again, this time using the R function that implements the Wilson Score method with a continuity correction. Then, assign the lowerbound and upperbound to `p11`.

```{r wilson-score}
# YOUR CODE HERE

# Replace "lowerbound" and "upperbound" with your answer
# If your answer is a number, make sure it doesn't have quotes around it
p11 <- c("lowerbound", "upperbound")
p11

# YOUR CODE HERE
```

```{r}
. = ottr::check("tests/p11.R")
```

\newpage

12. [1 mark] Create the 95% CI (using z = 1.96) again, this time using the Plus 4 method. Store your answer to `p12` using the following format: `p12 <- c(lowerbound, upperbound)`.

```{r plus-four}
# YOUR CODE HERE

# Replace "lowerbound" and "upperbound" with your answer
# If your answer is a number, make sure it doesn't have quotes around it
p12 <- c("lowerbound", "upperbound")
p12

# YOUR CODE HERE
```

```{r}
. = ottr::check("tests/p12.R")
```

\newpage

13. [1 mark] Create the 95% CI again, this time using the R function that implements the Clopper Pearson (Exact) method. Then, assign the lowerbound and upperbound to `p13`.

```{r exact-method}
# YOUR CODE HERE

# Replace "lowerbound" and "upperbound" with your answer
# If your answer is a number, make sure it doesn't have quotes around it
p13 <- c("lowerbound", "upperbound")
p13

# YOUR CODE HERE
```

```{r}
. = ottr::check("tests/p13.R")
```

\newpage

14. [2 marks] Here is a code template to help you to graphically present these estimates. Graphical presentations of estimates and their CIs is very useful for assessing whether the CIs overlap the null hypothesized value and tends to be better than presenting tables of estimates to readers of your research. You can fill in the values accordingly.

```{r p15}
# First make a tibble (an easy way to make a data frame) with the data about
# each confidence interval. To do this, replace each instance of 0.00 with the
# estimate from your calculations above.

library(ggplot2)
library(tibble)
sex_CIs <- tibble(method   = c("large sample", "Exact", "Wilson", "Plus 4"),
                  lower_CI = c(0.0           , 0.0    ,  0.0    ,  0.0),
                  upper_CI = c(0.0           , 0.0    ,  0.0    ,  0.0),
                  estimate = c(0.0           , 0.0    ,  0.0    ,  0.0)
                  )

# Build the ggplot incrementally, to understand how it works.
# Step 1: (qu: why do we put a horizontal line at 50?)
ggplot(data = sex_CIs, aes(x = method, y = estimate)) + 
  geom_point() + 
  geom_hline(aes(yintercept = 50), lty = 2)

# Step 2:
ggplot(data = sex_CIs, aes(x = method, y = estimate)) + 
  geom_point() +
  geom_hline(aes(yintercept = 50), lty = 2) +
  geom_segment(aes(xend = method, y = lower_CI, yend = upper_CI)) +
  labs(y = "Estimate with 95% CI")

# YOUR CODE HERE

# No autograder is provided for this question
```

What does `geom_segment()` do? In particular, what do `x`, `xend`, `y` and `yend` specify in this case?

_Type your answer here, replacing this text._

\newpage

15. [1 mark] Based on this plot, what can you say about the confidence intervals for the sex ratio in the high stress group?

_Type your answer here, replacing this text._

\newpage

### Submission

For assignments in this class, you'll be submitting using the **Terminal** tab in the pane below. In order for the submission to work properly, make sure that:

1. Any image files you add that are needed to knit the file are in the `src` folder and file paths are specified accordingly. 
2. You **have not changed the file name** of the assignment.
3. The file is saved (the file name in the tab should be **black**, not red with an asterisk).
4. The file knits properly.

Once you have checked these items, you can proceed to submit your assignment.

1. Click on the **Terminal** tab in the pane below.
2. Copy-paste the following line of code into the terminal and press enter.

cd; cd ph142-su21/lab/lab10; python3 turn_in.py

3. Follow the prompts to enter your Gradescope username and password. When entering your password, you won't see anything come up on the screen--don't worry! This is just for security purposes--just keep typing and hit enter.
4. If the submission is successful, you should see "Submission successful!" appear as output.
5. If the submission fails, try to diagnose the issue using the error messages--if you have problems, post on Piazza. 

The late policy will be strictly enforced, **no matter the reason**, including submission issues, so be sure to submit early enough to have time to diagnose issues if problems arise.
