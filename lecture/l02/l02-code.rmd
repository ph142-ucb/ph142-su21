---
title: "Working with data"

---

```{r load-libraries, echo = F, message=F, warning=FALSE}
library(ggplot2)
library(forcats)
library(fGarch) # don't need to know what this library does (used to make the skewed distributions)
library(readr)
```
Manipulate the data frame using the R package `dplyr`'s main functions:
    - `rename()`
    - `select()`
    - `arrange()`
    - `filter()`
    - `mutate()`
    - `group_by()`
    - `summarize()`


### readr is a library to import data into R

- To access readr's functions we load the library like this:

```{, warning=FALSE}
library(readr)
```

- Click the green arrow to run the code 
- A green rectangle that temporarily appears next to the code shows you that it 
has run.

### `read_csv()` to load the lake data in R
- `read_csv()` is a function from the `readr` library used to import csv files.
- code template: `your_data <- read_csv("pathway_to_data.csv")`
- The `<-` is called the **assignment operator**. It says to save the imported
data into an object called `your_data`.

```{r read-lake-data, message=FALSE}
lake_data <- read_csv("mercury-lake.csv")
```

### Exercise

1. Execute the above code using the green arrow 
2. Note that the data appears in the Environment pane in the top right. 
   - Notice the number of **observations** and the number of **variables**. 
3. Click the tiny table icon to the right of the `lake_data` in the Environment 
pane to open the **Viewer** tab and inspect the data.


## Describing your data:  what are you working with?

### Four R functions to get to know a dataset

* `head(your_data)`: Shows the first six rows of the supplied dataset
* `dim(your_data)`: Provides the number of rows by the number of columns
* `names(your_data)`: Lists the variable names of the columns in the dataset
* `str(your_data)`: Summarizes the above information and more


```{r head-lake-data}
# notice that if I put a # in front of a line of code it will not run
#head(lake_data)
#dim(lake_data)
#names(lake_data)
#str(lake_data)
```

### Unit of analysis
The unit of analysis is the major entity you are working with:

 - Bacteria
 - Laboratory test results
 - Individual People
 - Groups of people (couples, households)
 - Villages
 - Countries
 
 Which function in R lets us know how many units we have?
 

### Type of Variable

- **Categorical** variable: A variable that has grouping levels. Mathematically you can calculate the proportion (%) of individuals in each level of the category.
    - **Nominal** variables: have no underlying order or rank. E.g., hospital ID, HIV status (yes/no variables), race  
    - **Ordinal** variables: can be ordered or ranked. E.g., socio-economic status, BMI categories

- **Quantitative** variable: A continuous, numeric variable that you can perform mathematical operations on. Mathematically, we can you take the median or average of these variables
    - **Discrete** variables: can be counted. E.g., number of brain lesions, number of previous births
    - **Continuous** variables: can be measured precisely, with a ruler or scale. E.g, annual income, blood alcohol content, gestational age at birth

## dplyr functions for data manipulation

### Using `dplyr` functions for data manipulation {.bigger} 

- `rename()`
- `select()`
- `arrange()`
- `filter()`
- `mutate()`
- `group_by()`
- `summarize()`

### Load the `dplyr` library to access the functions

```{r load-dplyr, warning=FALSE}
library(dplyr)
```

- These messages mean that some functions (e.g., filter()) share names with 
functions from other libraries. So, when we use `filter()` we will now use the
`dplyr` version because the `stats` library version has been masked.
- You don't need to worry about masking for now.

### Function 1: rename()

What do you think rename does?

First print the names of the variables:
```{r print-variable-names}
names(lake_data)
```

Run the rename() function and assign it to `lake_data_tidy`:
```{r}
lake_data_tidy <- rename(lake_data, name_of_lake = lakes)
```

### Function 1: rename()
Then reprint the variable names:
```{r}
names(lake_data_tidy)
```

### Function 1: rename() multiple variables at once

You can rename multiple variables at once:

```{r rename-two-variables}
lake_data_tidy <- rename(lake_data, 
                         name_of_lake = lakes, 
                         ph_level = ph)
```

### Code template for rename() function

`new_dataset <- rename(old_dataset, new_name = old_name)`

Another way to write the above code is to use the **pipe** operator: `%>%`

`new_dataset <- old_dataset %>% rename(new_name = old_name)`

The pipe will become very useful in a few slides...

### Function 2: select()

Based on the output below, what do you think `select()` does? 

```{r select-first-three}
smaller_data <- select(lake_data, lakes, ph, chlorophyll)
names(smaller_data)
```

### Function 2: select()

* We use `select()` to select a subset of **variables**. 
* This is very handy if we inherit a large dataset with several variables that
we do not need.

### Function 2: "negative select()"

We can also use "negative `select()`" to deselect variables. Suppose we wanted
to keep all variables except for `age_data`:

```{r deselect-last-variable}
smaller_data_2 <- select(lake_data, - age_data)
names(smaller_data_2)
```

We place a negative sign in front of `age_data` to remove it from the dataset.

### Rewrite using the pipe operator

```{r}
smaller_data <- lake_data %>% select(lakes, ph, chlorophyll)
smaller_data_2 <- lake_data %>% select(- age_data)
```

* Going forward, we will use the pipe operator to write code using any `dplyr` functions
* This is because we can use the pipe to stack many `dplyr` functions in a row

### Function 3: arrange()

What does arrange do? First type `View(lake_data)` to look at the original data. Then 
run the code and examine its output below. What is different?:

```{r arrange-ph}
#View(lake_data)
lake_data %>% arrange(ph)
```

### Function 3: arrange() in descending order

```{r arrange-neg-ph}
lake_data %>% arrange(- ph)
```

### Function 3: arrange() by two variables

```{r arrange-age-and-ph}
lake_data %>% arrange(age_data, ph)
```

### Function 4: mutate()

- **`mutate()` is one of the most useful functions!** 
- It is used to add new variables to the dataset. Suppose that someone told you 
that the number of fish sampled was actually in hundreds, such that 5 is actually 500. You can use mutate to add a new variable to your dataset that is in the hundreds:

```{r mutate-fish-count}
lake_data_new_fish <- lake_data %>% 
  mutate(actual_fish_sampled = number_fish * 100)

#lake_data_new_fish
```

### Use `%>%` to append several lines of code together
- We have saved many of new datasets in our environment! 
- If these datasets were larger, they would take up a lot of space. 
- Rather than saving a new dataset each time, we can make successive changes
to one dataset like this:

```{r rename-select-and-mutate}
tidy_lake_data <- lake_data %>% 
  rename(name_of_lake = lakes) %>%
  mutate(actual_fish_sampled = number_fish * 100) %>%
  select(- age_data, - number_fish)
```

- When you see "%>%", say the words "and then...". For example, "Take `lake_data` and then rename `lakes` to name_of_lake, and then mutate..."

### Use `%>%` to "pipe" several lines of code together

```{r rename-select-and-mutate-eval}
tidy_lake_data <- lake_data %>% 
  rename(lake_name = lakes) %>%
  mutate(actual_fish_sampled = number_fish * 100) %>%
  select(- age_data, - number_fish)

tidy_lake_data
```

### Function 5: `filter()`

Filter is another very useful function! What might `filter()` do? 

### Function 5: `filter()`ing on numeric variables
We use filter to select which rows we want to keep in the dataset. Suppose you were only interested in lakes with `ph` levels of 7 or higher.

### Function 5: `filter()`ing on numeric variables
We use filter to select which rows we want to keep in the dataset. Suppose you were only interested in lakes with `ph` levels of 7 or higher.

```{r filter-on-ph}
lake_data_filtered <- lake_data %>% filter(ph > 7)
lake_data_filtered
```



### Function 5: `filter()`ing on character/string variables

Let's try a few more ways to `filter()` the data set since subsetting data is so 
important:

```{r filter-on-recent}
lake_data %>% filter(age_data == "recent")
```

- `==` is read as "is equal to"


### Function 5: `filter()`ing on character/string variables

```{r filter-not-on-recent}
lake_data %>% filter(age_data != "recent") 
```

- `!=` is read as "is not equal to"

### Function 5: `filter()`ing on character/string variables

```{r filter-on-name}
lake_data %>% filter(lakes %in% c("Alligator", "Blue Cypress")) 
```

- `%in%` is the "in" operator. We are selecting rows where the variable `lakes` 
belongs to the specified list.
- The `c()` combines "Alligator" and "Blue Cypress" into a list

### Function 5: multiple `filter()`s at once
```{r filter-multiple}
lake_data %>% filter(ph > 6, chlorophyll > 30)

#this is the same as:
lake_data %>% filter(ph > 6 & chlorophyll > 30)
```

- A comma or the "and" operator (`&`) are equivalent. Here they say, filter the dataset and keep only rows with `ph > 6` AND `chlorophyll > 30`

### Function 5: `filter()` using "or"
```{r filter-multiple-OR}
lake_data %>% filter(ph > 6 | chlorophyll > 30)
```

- `|` is the OR operator. At least one of `ph > 6` or `chlorophyll > 30` needs 
to be true.

### Functions 6 and 7: group_by() and summarize()

Let's execute the following code and see what it does.

```{r group_by-and-mean}
lake_data %>% 
  group_by(age_data) %>% 
  summarize(mean_ph = mean(ph))
```

What happened?

### Functions 6 and 7: group_by() and summarize()

Another one:

```{r group_by-and-mean-sd}
lake_data %>% 
  group_by(age_data) %>% 
  summarize(mean_ph = mean(ph),
            standard_deviation_ph = sd(ph))
```

### Recap: What functions did we use?

1. `library()` to load `readr` and `dplyr`.
2. `read_csv()` to read csv files from a directory.
3. `head()`, `str()`, `dim()`, and `names()` to look at our imported data.
4. `rename()` to rename variables in a data frame.
5. `select()` to select a subset of variables.
6. `arrange()` to sort a dataset according to one or more variables.
7. `mutate()` to create new variables.
8. `filter()` to select a subset of rows.
9. `group_by() and summarize()` to group the data by a categorial variable and 
calculate a statistic.
10. `mean()` and `sd()` to calculate the mean and standard deviation of variables.

### Recap: What operators did we use?

1. Assignment arrow: `<-`: This is our most important operator!
2. Greater than: `>` There are also: 
    - Less than: `<`
    - Greater than or equal to: `>=`, and,
    - Less than or equal to: `<=` 
4. Is equal to: `==`, and `!=` is not equal to
5. `%in%` to select from a list, where the list is created using `c()`, i.e., 
`lakes %in% c("Alligator", "Annie")`

### Reference material: Additional material

- [15 min intro to dplyr](https://www.youtube.com/watch?v=aywFompr1F4)
- [Data wrangling cheat sheet](https://www.rstudio.com/wp-content/uploads/2015/02/data-wrangling-cheatsheet.pdf)

### How to export from datahub and save onto your own computer

Some of you may want to edit this file in R markdown by adding notes, etc. In that
case, you can make your edits on datahub and save your updated file on the cloud.
You can additionally save your updated file locally on your computer. Here's how to do that:

1. In the File view window, click the checkbox beside the file you'd like to 
export 
2.  click More > Export. 

This will download the file to your computer's downloads folder.

## part II

```{r,include=FALSE,purl=FALSE}
library(knitr) # for include_graphics() 
library(dplyr)
library(forcats)
library(ggplot2)
library(fGarch) # don't need to know what this library does (used to make the skewed distributions)
```


### Lecture objectives part II
Describing your data:

1. Investigate measures of centrality
    - mean and median, and when they're the same vs. different
    
2. Investigate measures of spread
    - IQR, standard deviation, and variance
    
3. Create a visualization of the "five number summary"
    - boxplots using `ggplot`

4. Calculate the variance and standard deviation


   



### Skewed data

```{r, echo = F, out.width="80%", out.height="80%", fig.align='center'}
# STUDENTS: YOU DON'T NEED TO KNOW THE CODE IN THIS CODE CHUNK USED TO MAKE THIS PLOT.
x <- seq(0,1,length=100)
db <- dbeta(x, 2, 5)
db2 <- dbeta(x, 8, 2)

ggplot() + 
  geom_line(aes(x,db, col = "skewed right"), lwd = 2) + 
  geom_line(aes(x,db2, col = "skewed left"), lwd = 2) +
  labs(y = "Density") + theme_minimal(base_size = 18) + 
  theme(legend.title = element_blank())
```    

### Apartment rent in SF

Problem:  We want to understand how much it costs for a new resident to rent a 1 bedroom apartment in San Francisco

Plan:  Take a sample of 1000 apartment units listed for rent (currently available) and ask the rental price (excluding utilities)

Data:  Here I will present data that I simulated in r using a mean value published on rentjungle.com
- you will not be expected to do this or be tested on it.


```{r distribution-ex, echo = F, message=FALSE, warning=FALSE}
# This code chunk simulates rent price distributions under varying assumptions.
# Note to students: you won't be tested on your understanding of this code chunk.

set.seed(1236)
rent_n <- 1000
rent_mean <- 3300
rent_sd <- 500
rent_skew_factor <- 5
rent_sym <- rnorm(n = rent_n, mean = rent_mean, sd = rent_sd)
rent_sym_out_left <- c(rent_sym[ seq(1, rent_n - 3) ], 1200, 1250, 1500)
rent_sym_out_right <- rent_sym + c(rep(0, rent_n - 3), 6000, 5000, 5500)
rent_left_skew <- rsnorm(
  n = rent_n, mean = rent_mean,
  sd = rent_sd, xi = 1 / rent_skew_factor
)
rent_right_skew <- rsnorm(
  n = rent_n, mean = rent_mean,
  sd = rent_sd, xi = rent_skew_factor
)
rent_bimodal <- c(
  rnorm(n = rent_n / 2, mean = rent_mean, sd = 300),
  rnorm(n = rent_n / 2, mean = 2000, sd = 300)
)

rent_data <- data.frame(
  sym = rent_sym,
  left_skew = rent_left_skew,
  sym_out_left = rent_sym_out_left,
  sym_out_right = rent_sym_out_right,
  right_skew = rent_right_skew,
  bimodal = rent_bimodal
)

rm(rent_sym, rent_left_skew, rent_sym_out_left, 
   rent_sym_out_right, rent_right_skew, rent_bimodal)

rent_summs <- rent_data %>%
  summarize_all(list(mean = mean, median=median))

### now sample only 100 apartments
rent_smaller_n <- 100

rent_sym_small <- rnorm(n = rent_smaller_n, mean = rent_mean, sd = rent_sd)
rent_sym_out_left_small <- c(rent_sym_small[ seq(1, rent_smaller_n - 3) ], 1200, 1250, 1500)
rent_sym_out_right_small <- rent_sym_small + c(rep(0, rent_smaller_n - 3), 6000, 5000, 5500)

rent_data_small <- data.frame(
  sym = rent_sym_small,
  sym_out_left = rent_sym_out_left_small,
  sym_out_right = rent_sym_out_right_small
)

rent_summs_small <- rent_data_small %>%
  summarize_all(funs(mean, median))

rm(rent_sym_out_left_small, rent_sym_out_right_small, rent_sym_small)
```

### Example: Apartment rent in SF
Suppose that the distribution of rent prices looked like this. The green ticks underneath the histograms shows you the exact rent values that 
contribute data to each bin. 

```{r sym-plot, echo = F, fig.width=7, fig.height=4}
sym_plot <- ggplot(rent_data, aes(x = sym)) +
  geom_histogram(binwidth = 200, col = "white") +
  labs(x = "Monthly Rent ($)", 
       y = "Count of apartments",
       title = "Symmetric distribution in rental prices ($)") +
  geom_vline(xintercept = rent_summs$sym_mean) +
  geom_vline(xintercept = rent_summs$sym_median, col = "blue") +
  geom_text(aes(x = rent_summs$sym_mean + 150, y = 20),
            label = "Mean", check_overlap = T) +
  geom_text(aes(x = rent_summs$sym_median - 150, y = 20),
            label = "Median", check_overlap = T, col = "blue") +
  geom_rug(col = "#005824", alpha = 0.5) + #hex colours (see link below)
  theme_minimal(base_size = 15)

sym_plot
```

[Hex color picker](https://www.google.com/search?q=hex+colors+picker&oq=hex+colour&aqs=chrome.2.69i57j0l5.3494j0j1&sourceid=chrome&ie=UTF-8)

### Example: Apartment rent in SF
From last lecture:  We describe this distribution in terms of center, shape and spread:

- Center: Where is the center of the distribution?

- Shape:  Is this distribution unimodal or bimodal? 

- Spread:  How much variability is there between the lowest and highest rent values?

### Example: Apartment rent in SF
Summarizing numerically:
Center: 

```{r numerics}
# in base R
mean(rent_data[,"sym"])
median(rent_data[,"sym"])
```

```{r}
# using the summarize function and a pipe operator 
rent_data %>% summarize(
  mean=mean(sym),
  median = median(sym))
```

## Mean vs Median:  Outliers and sample size, skew, shape 

### When are the mean and median approximately equal?
- If your data has one peak (unimodal), is roughly symmetric, and does not have outliers
    - mean $\approx$ median, so provide either one in a summary 
 
### Example: Apartment rent in SF
Now suppose that there were three rents within the data set with much larger 
values than the rest of the distribution. Here is the plot for this updated data.

```{r sym-outlier-high-plot, echo = F, fig.width=9, fig.height=4}
sym_out_right_plot <- ggplot(rent_data, aes(x = sym_out_right)) +
  geom_histogram(binwidth = 200, col = "white") +
  xlab("Monthly Rent ($)") + ylab("Count") +
  ggtitle("Symmetric, but with outliers on the right, n=1000") +
  geom_vline(xintercept = rent_summs$sym_out_right_mean) +
  geom_vline(xintercept = rent_summs$sym_out_right_median, col = "blue") +
  geom_text(aes(x = rent_summs$sym_out_right_mean + 350, y = 20),
            label = "Mean", check_overlap = T) +
  geom_text(aes(x = rent_summs$sym_out_right_median - 350, y = 20),
            label = "Median", check_overlap = T, col = "blue") +
  geom_rug(col = "#005824", alpha = 0.5) +
  theme_minimal(base_size = 15)

sym_out_right_plot
```

- With 1000 sampled points the outliers do not have a large effect on the mean

### Example: Apartment rent in SF
Imagine instead, there were only 100 sampled points. Here, the outliers have a 
larger effect on the mean. **The mean is not resistant to outliers.**

```{r sym-outlier-high-smaller-n, echo = F, fig.width=9, fig.height=4}
sym_out_right_plot <- ggplot(rent_data_small, aes(x = sym_out_right)) +
  geom_histogram(binwidth = 400, col = "white") +
  xlab("Monthly Rent ($)") + ylab("Count") +
  ggtitle("Symmetric, but with outliers on the right, n=100") +
  geom_vline(xintercept = rent_summs_small$sym_out_right_mean) +
  geom_vline(xintercept = rent_summs_small$sym_out_right_median, col = "blue") +
  geom_text(aes(x = rent_summs_small$sym_out_right_mean + 350, y = 20),
            label = "Mean", check_overlap = T) +
  geom_text(aes(x = rent_summs_small$sym_out_right_median - 350, y = 20),
            label = "Median", check_overlap = T, col = "blue") +
  geom_rug(col = "#005824", alpha = 0.5) +
  theme_minimal(base_size = 15)

sym_out_right_plot
```

### Example: Apartment rent in SF
Consider instead what happens if there are many high-end apartments in the area. Here is the histogram of data for this example:

```{r right-skew-plot, echo = F, fig.width=9, fig.height=4}
right_skew_plot <- ggplot(rent_data, aes(x = right_skew)) +
  geom_histogram(binwidth = 150, col = "white") +
  xlab("Monthly Rent ($)") + ylab("Count") +
  ggtitle("Right-Skewed") +
  geom_vline(xintercept = rent_summs$right_skew_mean) +
  geom_vline(xintercept = rent_summs$right_skew_median, col = "blue") +
  geom_text(aes(x = rent_summs$right_skew_mean + 150, y = 20), label = "Mean", check_overlap = T) +
  geom_text(aes(x = rent_summs$right_skew_median - 150, y = 20), label = "Median", check_overlap = T, col = "blue") +
  geom_rug(col = "#005824", alpha = 0.5) +
  theme_minimal(base_size = 15)
right_skew_plot
```

### Example: Apartment rent in SF
Now, suppose that the sample of estimates did not look like the distribution in the previous example. Instead, it looked like this: 

```{r bimodal-plot, echo = F, fig.width=9, fig.height=4}
bi_plot <- ggplot(rent_data, aes(x = bimodal)) +
  geom_histogram(binwidth = 250, col = "white") +
  xlab("Monthly Rent ($)") + ylab("Count") +
  ggtitle("Bimodal") +
  geom_vline(xintercept = rent_summs$bimodal_mean) +
  geom_vline(xintercept = rent_summs$bimodal_median, col = "blue") +
  geom_text(aes(x = rent_summs$bimodal_mean + 150, y = 20),
            label = "Mean", check_overlap = T) +
  geom_text(aes(x = rent_summs$bimodal_median - 150, y = 20),
            label = "Median", check_overlap = T, col = "blue") +
  geom_rug(col = "#005824", alpha = 0.5) +
  theme_minimal(base_size = 15)
bi_plot
```


## Measures of spread

### The inter-quartile range (IQR)

- Q1 is the 1st quartile/the 25th percentile. 
    - 25% of individuals have measurements below Q1.

- Q2 is the 2nd quartile/the 50th percentile/the median. 
    - 50% of individuals have measurements below Q2.

- Q3, the 3rd quartile/the 75th percentile. 
    - 75% of individuals have measurements below Q3. 

- **Q1-Q3** is called the **inter-quartile range** (**IQR**). 
    - What percent of individuals lie in the IQR? `r #answer: the middle 50%`

- Know how to find Q1, Q2, and Q3 by hand for small lists of numbers

### Quantiles using R
`quantile(variable, 0.25)`

```{r quantiles}
rent_data %>% summarize(
  Q1 = quantile(sym, 0.25),
  median = median(sym),
  Q3 = quantile(sym, 0.75)
  )
```

### R's quantile function:  Note

- `quantile(variable, 0.25)` will not always give the exact same answer you 
calculate by hand
- The R function is optimized for its statistical properties and is slightly 
different than the book's method
- To get the exact same answer as by hand use `quantile(data, 0.25, type = 2)`
- You may use either one in this class. Most commonly, people do not specify
`type=2`

### Another measure of spread: The (full) range
- The difference between the **minimum** and **maximum** value

### Concise information about spread and center: The five number summary

- **The five number summary** (min, Q1,median,Q3, max) is a quick way to communicate a distribution's 
center and spread.
- Based on the summary you can describe the full range of a 
dataset, where the middle 50% of the data lie, and the middle value.

### `dplyr`'s summarize() to calculate the five number summary
Using our original example of rent data:

```{r five-number-summary2}
rent_data %>% summarize(
  min = min(sym),
  Q1 = quantile(sym, 0.25),
  median = median(sym),
  Q3 = quantile(sym, 0.75),
  max = max(sym)
)
```

## Example:  Hospital cesarean delivery rates

### Example:  Hospital cesarean delivery rates
These data were provided by the first author (Kozhimannil) of a manuscript 
published in the journal *Health Affairs*. [link](https://www.healthaffairs.org/doi/10.1377/hlthaff.2012.1030)

From the article:
Cesarean delivery is the most commonly performed surgical procedure in the United States, and cesarean rates are increasing. 
In its Healthy People 2020 initiative, the Department of Health and Human Services put forth clear, authoritative public health goals recommending a 10 percent reduction in both primary and repeat cesarean rates, from 26.5 percent to 23.9 percent, and from 90.8 percent to 81.7 percent, respectively.

A targeted approach to achieving such reductions might focus on hospitals with exceptionally high cesarean rates. However, adopting such a strategy requires quantification of hospital-level variation in cesarean delivery rates.

### Example:  Hospital cesarean delivery rates
Problem:  To characterize the variation in cesarean rates between Hospitals in the United States

Plan:  Collect existing data from a variety of institutions for one year and compare rates of cesarean delivery.
They also looked at cesarean rates among only low risk births at each institution.  Why might this be important?

Data:  For this article, they worked with 2009 data from 593 US hospitals nationwide

### Example:  Hospital cesarean delivery rates
We start by importing the data:

```{r import-tidy-cs-data, message=FALSE, warning=FALSE}
library(readxl) 
# this library helps with reading xlsx and xls files into R
CS_dat <- read_xlsx("Kozhimannil_Ex_Cesarean.xlsx", sheet = 1)
```

### Example:  Hospital cesarean delivery rates

```{r import-tidy-cs-data2}
head(CS_dat)
```

### Example:  Hospital cesarean delivery rates

```{r import-tidy-cs-data3}
names(CS_dat) 
```

let's take a moment to discuss variable names containing spaces

### Sidenote on variable names containing spaces

- Two variables in `CS_dat` contain spaces. 
- We generally want to remove spaces from variable names. 

* Question: Which `dplyr` function can we use to change the variable names?
* Answer: `rename(new_name = old_name)` can be used. When the old variable name contains spaces, you need to place back ticks around it like this: 


```{r rename-vars-with-spaces}
CS_dat <- CS_dat %>% rename(cs_rate = `Cesarean rate *100`,
                            low_risk_cs_rate = `Low Risk Cearean rate*100`)
```

- See [this paper](https://www.tandfonline.com/doi/abs/10.1080/00031305.2017.1375989) for tips on storing data in Excel for later analysis. 

### Tidy the data for analysis

For our example, we are only interested in each hospital's cesarean delivery rate,
the rate for lower risk pregnancies, and the number of births at the hospital.

```{r tidy-the-data}
CS_dat <- CS_dat %>%
  select(Births, cs_rate,low_risk_cs_rate) %>%
  rename(num_births = Births)
```

### Analysis: Histogram of cesarean delivery rates across US hospitals
ggplot(CS_dat, aes(x = cs_rate)) +
 
  geom_histogram(col = "white", binwidth = 5) +
 
  labs( x = "Cesarean delivery rate (%)", y = "Count",
 
    caption = "Data from: Kozhimannil, Law, and Virnig. Health Affairs. 2013;32(3):527-35.") +
 
  geom_rug(alpha = 0.2, col = "forest green") + #alpha controls transparency
 
  theme_minimal(base_size = 15)

### Histogram of cesarean delivery rates across US hospitals
```{r histogram-cs, fig.width=8, fig.height=4,echo=F}
ggplot(CS_dat, aes(x = cs_rate)) +
  geom_histogram(col = "white", binwidth = 5) +
  labs( x = "Cesarean delivery rate (%)", y = "Count",
    caption = "Data from: Kozhimannil, Law, and Virnig. Health Affairs. 2013;32(3):527-35.") +
  geom_rug(alpha = 0.2, col = "forest green") + #alpha controls transparency
  theme_minimal(base_size = 15)
```

### Spread of cesarean delivery rates across US hospitals
- What can you say about this distribution? Would you expect so much variation 
across hospitals in their rates of cesarean delivery? 
- Let's describe the **spread** of these data using the methods from Chapter 2.


### Quantiles 

```{r quantiles2}
CS_dat %>% summarize(
  Q1 = quantile(cs_rate, 0.25),
  median = median(cs_rate),
  Q3 = quantile(cs_rate, 0.75)
  )
```


### `dplyr`'s summarize() to calculate the five number summary
```{r five-number-summary}
CS_dat %>% summarize(
  min = min(cs_rate),
  Q1 = quantile(cs_rate, 0.25),
  median = median(cs_rate),
  Q3 = quantile(cs_rate, 0.75),
  max = max(cs_rate)
)
```

### Histogram of low risk cesarean delivery rates across US hospitals
```{r histogram-lcs, fig.width=8, fig.height=4,echo=F}
ggplot(CS_dat, aes(x = low_risk_cs_rate)) +
  geom_histogram(col = "white", binwidth = 5) +
  labs( x = "Low risk Cesarean delivery rate (%)", y = "Count",
    caption = "Data from: Kozhimannil, Law, and Virnig. Health Affairs. 2013;32(3):527-35.") +
  geom_rug(alpha = 0.2, col = "forest green") + #alpha controls transparency
  theme_minimal(base_size = 15)
```

### `dplyr`'s summarize() to calculate the five number summary
```{r five-number-summaryL}
CS_dat %>% summarize(
  min = min(low_risk_cs_rate),
  Q1 = quantile(low_risk_cs_rate, 0.25),
  median = median(low_risk_cs_rate),
  Q3 = quantile(low_risk_cs_rate, 0.75),
  max = max(low_risk_cs_rate)
)
```


## Sample variance and standard deviation

### Sample variance and standard deviation

Let $s^2$ represent the variance of a sample. Then,

$$s^2 = \frac{(x_1-\bar{x})^2 + (x_2-\bar{x})^2 + ... + (x_n-\bar{x})^2}{n-1}$$

$$s^2 = \frac{1}{n-1}((x_1-\bar{x})^2 + (x_2-\bar{x})^2 + ... + (x_n-\bar{x})^2)$$

$$s^2 = \frac{1}{n-1}\sum_{i=1}^n(x_i-\bar{x})^2$$

Let $s$ represent the standard deviation of a sample. Then,

$$s = \sqrt{\frac{1}{n-1}\sum_{i=1}^n(x_i-\bar{x})^2}$$

### Sample variance and standard deviation

- Some intuition on why we divide by n-1: [link](https://www.khanacademy.org/math/ap-statistics/summarizing-quantitative-data-ap/more-standard-deviation/v/review-and-intuition-why-we-divide-by-n-1-for-the-unbiased-sample-variance)

### `dplyr`'s summarize() to calculate the standard deviation and the variance
```{r five-number-summary-plus, echo = T}
CS_dat %>% summarize(
  cs_sd = sd(cs_rate),
  cs_var = var(cs_rate)
)
```


### Example:  Hospital cesarean delivery rates

What might we conclude from these data?

### Example:  Hospital cesarean delivery rates
From the article:

"we found that cesarean rates varied tenfold across hospitals, from 7.1 percent to 69.9 percent. Even for women with lower-risk pregnancies, in which more limited variation might be expected, cesarean rates varied fifteenfold, from 2.4 percent to 36.5 percent. Thus, vast differences in practice patterns are likely to be driving the costly overuse of cesarean delivery in many US hospitals. "

## Box plots

### Box plots provide a nice visual summary of the center and spread
Also called box and whisker plots

The box:

- The centre line is the median
- The top of the box is the Q3
- The bottom of the box is the Q1

The whiskers - depends:

- The top of the top whisker is either the max value, or equal to the highest point that is below Q3 + 1.5*IQR
- The bottom of the bottom whisker is either min value, or equal to the lowest point that is above Q1 - 1.5*IQR
- In plots where the whiskers are **not** the min and max, the data points above and below the whiskers are the outliers

### Box plots in R 

ggplot(CS_dat, aes(y = cs_rate)) +
 
  **geom_boxplot**() +
 
  ylab("Cesarean delivery rate (%)") +
 
  labs(title = "Box plot of the CS rates across US hospitals",
 
       caption = "Data from: Kozhimannil et al. 2013.") +
 
  theme_minimal(base_size = 15) +
 
  scale_x_continuous(labels = NULL)   # removes the labels from the x axis

### Box plots provide a nice visual summary of the center and spread
```{r box-plot-ex, width = 2, fig.width = 4.5, fig.height = 5.5, echo=F}
ggplot(CS_dat, aes(y = cs_rate)) +
  geom_boxplot() +
  ylab("Cesarean delivery rate (%)") +
  labs(title = "Box plot of the CS rates across \nUS hospitals",
       caption = "Data from: Kozhimannil et al. 2013.") +
  theme_minimal(base_size = 15) +
  scale_x_continuous(labels = NULL) 
  # removes the labels from the x axis
```



### R Recap: What new functions did we use?
1. `quantile(data, 0.25)`, `quantile(data, 0.75)` for Q1 and Q3, respectively
2. `min()` and `max()` for the full range of the data
3. `sd()` and `var()` for sample standard deviation and variance
4. Used the above within `summarize()` to easily output these measures
4. `ggplot`'s `geom_boxplot`

    




