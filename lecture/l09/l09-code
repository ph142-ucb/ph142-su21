---
title: "Introduction to Probability"
output: pdf_document
---

<!-- libraries -->
```{r,include=FALSE,purl=FALSE}
library(knitr) # for include_graphics() 
library(dplyr)
```

<!-- define default size for R graphics -->
```{r,include=FALSE,purl=FALSE}
outputFormat<-opts_knit$get('rmarkdown.pandoc.to')
if(outputFormat=="beamer"){
  opts_chunk$set(fig.width=6,fig.height=4)
}
```

<!-- define function for external images -->
```{r,include=FALSE,purl=FALSE}
image<-function(ff,ss,cc=NULL,ll=NULL){
  if(is.null(cc)){
    paste('\\centering','\n',
          '\\includegraphics[scale=',ss,']{',ff,'}',
          sep='')
  } else {
    paste('\\centering','\n',
          '\\copyrightbox[b]{',
          '\\includegraphics[scale=',ss,']{',ff,'}',
          '}{\\raggedleft{\\tiny \\href{',ll,'}{',cc,'}}}',
          sep='')    
  }
}
```

<!-- define function for links -->
```{r,include=FALSE,purl=FALSE}
link<-function(tt,ll){
  paste('[\\textcolor[HTML]{ffa328}{\\ul{',tt,'}}]','(',ll,')',sep='')
}
```


```{r load-libraries, message=F, warning=FALSE, echo=F}
library(ggplot2)
library(dplyr)
library(patchwork)
library(readxl)
library(ggrepel)
library(gridExtra)
library(cowplot)
```
### From B&M: How common is the common cold?

- Suppose that there are 100,000 people in your community. You work for your 
community's public health office and want to estimate the number of people who 
had a common cold. You are not able to sample everyone but suppose you could 
randomly call people in your community and ask them "Did you have a cold 
yesterday?" and then calculate the proportion of the sample who had a cold. 

### From B&M: How common is the common cold?

- Here are the dimensions, a data frame for the **whole population**, and the mean 
of the variable `had_cold_yesterday`:

```{r create-cold-data, echo=F}
#students: you don't need to understand this code chunk yet. 

population_size <- 100000
prob_cold <- 0.112
id <- 1:population_size
set.seed(1234)
# Generate n random binomial samples (coin flips) where 
# probability of cold (heads) is prob_cold
had_cold_yesterday <- rbinom(n = population_size, size = 1, prob = prob_cold) 
#each person has an 11.2% chance of having the common cold yesterday
cold_data <- data.frame(id, had_cold_yesterday)
```

```{r}
dim(cold_data)
cold_data %>% summarize(population_mean = mean(had_cold_yesterday))
```

- Note that the mean of a 0/1 variable is called a **proportion**. This is because 
the mean is the number of individuals with a cold (coded as `had_cold_yesterday = 1`)
divided by the total number of individuals.

### From B&M page 216: How common is the common cold?

How big should your sample size be?

- We want to sample enough people such that the proportion of those with colds
in the sample is close to the proportion of those with colds in the population

- Let's take samples of size 5, 100, and so on using `dplyr`'s `sample_n`
function:

```{r the-smallest-samples}
sample_5 <- dplyr::sample_n(tbl = cold_data, size = 5)
sample_100 <- dplyr::sample_n(tbl = cold_data, size = 100)
sample_1000 <- dplyr::sample_n(tbl = cold_data, size = 1000)
sample_10000 <- dplyr::sample_n(tbl = cold_data, size = 10000)
sample_100000 <- dplyr::sample_n(tbl = cold_data, size = 100000)
```

### Now estimate the proportion of those with a cold in the random samples

```{r results-from-the-smallest-samples, echo=FALSE}
sample_5 %>% summarize(sample_mean_n5 = mean(had_cold_yesterday))
sample_100 %>% summarize(sample_mean_n100 = mean(had_cold_yesterday))
sample_1000 %>% summarize(sample_mean_n1k = mean(had_cold_yesterday))
sample_10000 %>% summarize(sample_mean_n10k = mean(had_cold_yesterday))
sample_100000 %>% summarize(sample_mean_n100k = mean(had_cold_yesterday))
```

### Estimate the proportion of those with a cold in the random samples
- What do you notice about the proportion estimates? 
- Do they approach the true estimate as the sample size increases?

### How many people should we sample?

- So we know we should sample more than five people, but feasibly can't sample 
everyone. 

- We need to sample *enough* people to reasonably estimate the true chance of 
having a cold. But how many is enough?

### Look at the sample's estimated proportion as a function of sample size

* To help us decide I first sampled one person and took the mean of that sample.

* Then I added another person and took the mean of that sample of size 2 (n=2).
... and so on, until I had 5000 people. 

* The plot on the next slide shows the estimated proportion vs. the sample size.

```{r three-growing-samples-of-5000, echo=F, eval=F}
# students, you don't need to understand this code chunk

# inspirational TODO for CR (for future reference, not for right now): make this into a 
# shiny app that updates a growing plot after continuing to add one more person 
# into the sample to show how the estimate updated each time.

cold_data_copy <- cold_data
cold_data_copy$in_sample1 <- 0
cold_data_copy$in_sample2 <- 0
cold_data_copy$in_sample3 <- 0
grow_data1 <- grow_data2 <- grow_data3 <- NULL

for(i in 1:5000){
  sample_1 <- cold_data_copy %>% 
    filter(in_sample1 == 0) %>% 
    sample_n(1)
  cold_data_copy$in_sample1[cold_data_copy$id == sample_1$id] <- 1
  new <- cold_data_copy %>% filter(in_sample1 == 1) %>% 
    summarize(mean = mean(had_cold_yesterday),
              sample_size = n())
  grow_data1 <- rbind(grow_data1, new)
  
  sample_2 <- cold_data_copy %>% 
    filter(in_sample2 == 0) %>% 
    sample_n(1)
  cold_data_copy$in_sample2[cold_data_copy$id == sample_2$id] <- 1
  new <- cold_data_copy %>% 
    filter(in_sample2 == 1) %>% 
    summarize(mean = mean(had_cold_yesterday),
              sample_size = n())
  grow_data2 <- rbind(grow_data2, new)
  
  sample_3 <- cold_data_copy %>% 
    filter(in_sample3 == 0) %>% 
    sample_n(1)
  cold_data_copy$in_sample3[cold_data_copy$id == sample_3$id] <- 1
  new <- cold_data_copy %>% 
    filter(in_sample3 == 1) %>% 
    summarize(mean = mean(had_cold_yesterday),
              sample_size = n())
  grow_data3 <- rbind(grow_data3, new)
}

grow_data1 <- grow_data1 %>% mutate(sample = "First sample")
grow_data2 <- grow_data2 %>% mutate(sample = "Second sample")
grow_data3 <- grow_data3 %>% mutate(sample = "Third sample")

grow_data <- rbind(grow_data1, grow_data2, grow_data3)
## Saving image because this part takes a long time
save.image("../Data/chp9.rdata")
```

### Estimated proportion vs. sample size for n = 250

```{r first-sample-250, echo=F,fig.align='center', message=F, warning=F, out.width = "80%"}
# students, don't worry about this code

load("chp9.rdata")
segment1 <- data.frame(x1 = 1, x2 = 1000, y1 = prob_cold, y2 = prob_cold)
segment2 <- data.frame(x1 = 1, x2 = 1000, y1 = prob_cold + 0.05, y2 = prob_cold + 0.05)
segment3 <- data.frame(x1 = 1, x2 = 1000, y1 = prob_cold - 0.05, y2 = prob_cold - 0.05)
segment4 <- data.frame(x1 = 1, x2 = 1000, y1 = prob_cold + 0.02, y2 = prob_cold + 0.02)
segment5 <- data.frame(x1 = 1, x2 = 1000, y1 = prob_cold - 0.02, y2 = prob_cold - 0.02)

p1 <- ggplot(grow_data %>% dplyr::filter(sample_size < 250, sample == "First sample"), 
             aes(x = sample_size, y = mean)) + 
  geom_segment(aes(y = y1, yend = y2, x = x1, xend = x2), data = segment1) + 
  geom_segment(aes(y = y1, yend = y2, x = x1, xend = x2), data = segment2, lty = 3) + 
  geom_segment(aes(y = y1, yend = y2, x = x1, xend = x2), data = segment3, lty = 3) + 
  geom_segment(aes(y = y1, yend = y2, x = x1, xend = x2), data = segment4, lty = 3) + 
  geom_segment(aes(y = y1, yend = y2, x = x1, xend = x2), data = segment5, lty = 3) + 
  geom_text(aes(y = prob_cold + 0.005, x = 800), label = "pop'n proportion", check_overlap = T) +
  geom_text(aes(y = prob_cold + 0.05, x = 900), label = "+ 5", check_overlap = T) + 
  geom_text(aes(y = prob_cold - 0.05, x = 900), label = "- 5", check_overlap = T) + 
  geom_text(aes(y = prob_cold + 0.02, x = 900), label = "+ 2", check_overlap = T) + 
  geom_text(aes(y = prob_cold - 0.02, x = 900), label = "- 2", check_overlap = T) + 
  geom_line(aes(col = factor(sample))) + 
  labs(y = "Estimated proportion", x = "Sample size", 
       title = "n=250, one sample") +
  theme_minimal(base_size = 15) + 
  scale_x_continuous(breaks = seq(0, 1000, 200)) +
  scale_y_continuous(labels = scales::percent, breaks = seq(0, 0.18, 0.02), 
                     limits = c(0, 0.18)) + 
  theme(panel.grid.minor = element_blank(), legend.position = "top", legend.title = element_blank())

# Now we add the line for the second sample of 250:
p2 <- ggplot(grow_data %>% dplyr::filter(sample_size < 250, sample != "Third sample"), 
             aes(x = sample_size, y = mean)) + 
  geom_segment(aes(y = y1, yend = y2, x = x1, xend = x2), data = segment1) + 
  geom_segment(aes(y = y1, yend = y2, x = x1, xend = x2), data = segment2, lty = 3) + 
  geom_segment(aes(y = y1, yend = y2, x = x1, xend = x2), data = segment3, lty = 3) + 
  geom_segment(aes(y = y1, yend = y2, x = x1, xend = x2), data = segment4, lty = 3) + 
  geom_segment(aes(y = y1, yend = y2, x = x1, xend = x2), data = segment5, lty = 3) + 
  geom_text(aes(y = prob_cold+0.005, x = 800), label = "pop'n proportion", check_overlap = T) +
  geom_text(aes(y = prob_cold + 0.05, x = 900), label = "+ 5", check_overlap = T) + 
  geom_text(aes(y = prob_cold - 0.05, x = 900), label = "- 5", check_overlap = T) + 
  geom_text(aes(y = prob_cold + 0.02, x = 900), label = "+ 2", check_overlap = T) + 
  geom_text(aes(y = prob_cold - 0.02, x = 900), label = "- 2", check_overlap = T) + 
  geom_line(aes(col = factor(sample))) + 
  labs(y = "Estimated proportion", x = "Sample size",
       title = "n=250, two samples") +
  theme_minimal(base_size = 15) +
  scale_x_continuous(breaks = seq(0, 1000, 200)) +
  scale_y_continuous(labels = scales::percent, breaks = seq(0, 0.18, 0.02), 
                     limits = c(0, 0.18)) +
  theme(panel.grid.minor = element_blank(), legend.position = "top", legend.title = element_blank()) 
  
p1 + p2 + plot_layout()  
```

### Estimated proportion vs. sample size for n = 500 

- Increase the sample size how the estimate becomes closer to the true value
- Add in a third sample to compare how different samples perform in the short 
vs. the long run 

```{r sample-250-500, echo=F, fig.align='center', message=F, warning=F, out.width="80%"}
p3 <- ggplot(grow_data %>% dplyr::filter(sample_size < 250), aes(x = sample_size, y = mean)) + 
  geom_segment(aes(y = y1, yend = y2, x = x1, xend = x2), data = segment1) + 
  geom_segment(aes(y = y1, yend = y2, x = x1, xend = x2), data = segment2, lty = 3) + 
  geom_segment(aes(y = y1, yend = y2, x = x1, xend = x2), data = segment3, lty = 3) + 
  geom_segment(aes(y = y1, yend = y2, x = x1, xend = x2), data = segment4, lty = 3) + 
  geom_segment(aes(y = y1, yend = y2, x = x1, xend = x2), data = segment5, lty = 3) + 
    geom_text(aes(y = prob_cold+0.005, x = 800), label = "pop'n proportion", check_overlap = T) +
  geom_text(aes(y = prob_cold + 0.05, x = 900), label = "+ 5", check_overlap = T) + 
  geom_text(aes(y = prob_cold - 0.05, x = 900), label = "- 5", check_overlap = T) + 
  geom_text(aes(y = prob_cold + 0.02, x = 900), label = "+ 2", check_overlap = T) + 
  geom_text(aes(y = prob_cold - 0.02, x = 900), label = "- 2", check_overlap = T) + 
  geom_line(aes(col = factor(sample))) + 
  labs(y = "Estimated proportion", x = "Sample size", 
       title = "n = 250, 3 samples") + 
  scale_x_continuous(breaks = seq(0, 1000, 200)) +
  scale_y_continuous(labels = scales::percent, breaks = seq(0, 0.80, 0.02)) +
  theme_minimal(base_size = 15) +
  theme(legend.position="none", panel.grid.minor = element_blank())

p4 <- ggplot(grow_data %>% dplyr::filter(sample_size < 500), aes(x = sample_size, y = mean)) + 
  geom_segment(aes(y = y1, yend = y2, x = x1, xend = x2), data = segment1) + 
  geom_segment(aes(y = y1, yend = y2, x = x1, xend = x2), data = segment2, lty = 3) + 
  geom_segment(aes(y = y1, yend = y2, x = x1, xend = x2), data = segment3, lty = 3) + 
  geom_segment(aes(y = y1, yend = y2, x = x1, xend = x2), data = segment4, lty = 3) + 
  geom_segment(aes(y = y1, yend = y2, x = x1, xend = x2), data = segment5, lty = 3) + 
    geom_text(aes(y = prob_cold+0.005, x = 800), label = "pop'n proportion", check_overlap = T) +
  geom_text(aes(y = prob_cold + 0.05, x = 900), label = "+ 5", check_overlap = T) + 
  geom_text(aes(y = prob_cold - 0.05, x = 900), label = "- 5", check_overlap = T) + 
  geom_text(aes(y = prob_cold + 0.02, x = 900), label = "+ 2", check_overlap = T) + 
  geom_text(aes(y = prob_cold - 0.02, x = 900), label = "- 2", check_overlap = T) + 
  geom_line(aes(col = factor(sample))) + 
  labs(x = "Sample size", y = "Estimated proportion", 
       title = "n = 500, 3 samples") + 
  scale_x_continuous(breaks = seq(0, 1000, 200)) +
  scale_y_continuous(labels = scales::percent, breaks = seq(0, 0.80, 0.02)) +
  theme_minimal(base_size = 15) +
  theme(legend.position="none", panel.grid.minor = element_blank())

segment6 <- data.frame(x1 = 1, x2 = 5000, y1 = prob_cold, y2 = prob_cold)
segment7 <- data.frame(x1 = 1, x2 = 5000, y1 = prob_cold + 0.05, y2 = prob_cold + 0.05)
segment8 <- data.frame(x1 = 1, x2 = 5000, y1 = prob_cold - 0.05, y2 = prob_cold - 0.05)
segment9 <- data.frame(x1 = 1, x2 = 5000, y1 = prob_cold + 0.02, y2 = prob_cold + 0.02)
segment10 <- data.frame(x1 = 1, x2 = 5000, y1 = prob_cold - 0.02, y2 = prob_cold - 0.02)

p3 + p4 + plot_layout()
```

### Estimated proportion vs. sample size for n = 5000

```{r sample-5000, echo=F, fig.align='center', message=F, warning=F, out.width="80%"}
p5 <- ggplot(grow_data %>% dplyr::filter(sample_size < 5000), aes(x = sample_size, y = mean)) + 
  geom_segment(aes(y = y1, yend = y2, x = x1, xend = x2), data = segment6) + 
  geom_segment(aes(y = y1, yend = y2, x = x1, xend = x2), data = segment7, lty = 3) + 
  geom_segment(aes(y = y1, yend = y2, x = x1, xend = x2), data = segment8, lty = 3) + 
  geom_segment(aes(y = y1, yend = y2, x = x1, xend = x2), data = segment9, lty = 3) + 
  geom_segment(aes(y = y1, yend = y2, x = x1, xend = x2), data = segment10, lty = 3) + 
  geom_text(aes(y = prob_cold+0.005, x = 5050), label = "pop'n proportion", check_overlap = T) +
  geom_text(aes(y = prob_cold + 0.05, x = 4200), label = "+5", check_overlap = T) + 
  geom_text(aes(y = prob_cold - 0.05, x = 4200), label = "-5", check_overlap = T) + 
  geom_text(aes(y = prob_cold + 0.02, x = 4200), label = "+2", check_overlap = T) + 
  geom_text(aes(y = prob_cold - 0.02, x = 4200), label = "-2", check_overlap = T) + 
  geom_line(aes(col = factor(sample))) + 
  labs(y = "Estimated proportion", x = "Sample size", 
       title = "n = 5000, 3 samples") + 
  theme_minimal(base_size = 15) +
  scale_x_continuous(breaks = seq(0, 5000, 500)) +
  scale_y_continuous(labels = scales::percent, breaks = seq(0, 0.80, 0.02))  +  
  theme(panel.grid.minor = element_blank(), legend.position = "top", legend.title = element_blank())

p5
```

### Summary of the example on estimating the proportion with a cold

- As the sample size increases, the estimated proportion becomes closer to the 
true proportion
- Random samples of the same size will provide different estimates of the true 
proportion, but will be closer to each other (and the true value) if they are 
"large enough"


### Composite Events
Imagine we have 100 students in a classroom.  
```{r venscomposit, echo=FALSE, message=FALSE, warning=FALSE}
#Students do not need to know how to do this
# install.packages('VennDiagram')
library(VennDiagram)
## cat.pos - position of category titles, represented by degree from the
## middle of the circle

## cat.dist - distance of the category titles from the edge of the circle

grid.newpage()
draw.pairwise.venn(30, 40, 15, category = c("Undegraduate", "Wears glasses"), lty = rep("blank", 
    2), fill = c("light blue", "pink"), alpha = rep(0.5, 2), cat.pos = c(0, 
    0), cat.dist = rep(0.025, 2))
```


### Composite Events
There are 40 students who wear glasses, and 30 who are undergraduates.

Based on the Venn diagram, what is P(Glasses)?  

What is the complement $P(\overline{Glasses})$

What is the union of these two events $P(Glasses\cup Undergraduate)$

What is the intersect of these two events $P(Glasses \cap Undergraduate)$

### Composite Events

If we toss a coin twice, what are the possible composite events in our sample space?

What is the probability of tossing a combination of one Heads and one Tails?

What is the complement of that?



### Disjoint events
If two events have a joint probability of 0 (i.e., no overlap in their event spaces $P(A\cap B)=0$) then they are **disjoint** and the probability of either event occurring is the summation of their individual probabilities. 

 $P(A or B) = P(A) + P(B)$, if A and B are disjoint events.
    
Disjoint events are also described as **mutually exclusive** meaning that it is not possible to have both events

## Discrete probability models

### Discrete probability model

- A probability model with a sample space made up of a list of individual outcomes
is called discrete
- To assign probabilities in a discrete model, list the probabilities of all the
individual outcomes. These probabilities must be numbers between 0 and 1 and must
sum to 1. The probability of any event is the sum of the probabilities of the
outcomes making up the event.

### Discrete probability model example

For example, we could survey a sample of people and ask them their marital status. 
Based on this survey we can calculate the portion of each event in the sample space:

| Single | Married | Divorced | Widowed |
|:------:|:-------:|:--------:|:-------:|
| 47%    | 30%     | 18%      | 5%      |

This is a discrete probabiltiy model shown in a table. How else could you display these data?

### Continuous probability model

- A continuous probability model assigns probabilities as areas under a **density**
curve. The area under the curve and between a range of specified values on the horizontal 
axis is the probability of an outcome in that range.
- What is a density curve? 

### Density curves

- Density curves are also known as **probabilty density functions**
- You can think of density curves as **smoothed histograms**. 


### Density curves using `geom_density()`

- Recall the data on cesarean delivery rates across hospitals in the US. We can 
use these data to also make a density plot (also called density curve):

```{r cs-variation-plot-example, echo = F, warning=F, message=F, out.width="80%"}
CS_dat <- read_xlsx("Ch02_Kozhimannil_Ex_Cesarean.xlsx", sheet = 1)

CS_dat <- CS_dat %>% 
  dplyr::select(Births, `Cesarean rate *100`) %>%
  dplyr::rename(num_births = Births, cs_rate = `Cesarean rate *100`)

CS_dat <- CS_dat %>% dplyr::mutate(cs_rate_binned = cut(cs_rate, 32))

## Basic histogram from cesarean delivery. Each bin is 2 wide.
basic.hist <- ggplot(CS_dat, aes(x=cs_rate)) + 
  geom_histogram(binwidth = 2) +
  ggtitle("Basic histogram") + 
  theme_minimal(base_size = 15)

# Draw with black outline, white fill
better.hist <- ggplot(CS_dat, aes(x=cs_rate)) + 
  geom_histogram(binwidth = 2, colour="black", fill="white") + 
  ggtitle("Better histogram") + 
  theme_minimal(base_size = 15)

# Density curve (students: be able to make density plots like this)
basic.density <- ggplot(CS_dat, aes(x=cs_rate)) + 
  geom_density() + 
  labs(title = "Basic density") + 
  theme_minimal(base_size = 15)

# Histogram overlaid with density curve
# overlaying density plots onto histograms is a bit tricky,
# so don't worry about learning this bit of code.
density.hist <- ggplot(CS_dat, aes(x=cs_rate)) + 
  geom_histogram(aes(y=..density..),      # Histogram with density instead of count on y-axis
                   binwidth=2,
                   colour="black", fill="white") +
  geom_density(alpha=.2, fill="#FF6666") +  # Overlay with transparent density plot
  ggtitle("Histogram and density") + 
  theme_minimal(base_size = 15)

basic.hist + better.hist + basic.density + density.hist + plot_layout()

# plotting formatting ideas from : http://www.cookbook-r.com/Graphs/Plotting_distributions_(ggplot2)/

# this summary dataset shows the relationship between the proportion in each bin and the density
# since density is an area, you need to take the proportion (height) and divide by the bin width
# (here it is 2.02 based on how we chose our bins) to get the density.
CS.summary <- CS_dat %>% 
  group_by(cs_rate_binned) %>% 
  summarize(n = n()) %>%
  mutate(prop = round((n/sum(n))*100,2), 
         density = (n/sum(n))/2.02) 
```

### Density curves

- From this plot, we can see that the density curve approximates the shape of 
the histogram very well. 
- Remember because there are infinitely many cesarean delivery rates that could 
be observed between 0 and 1 it is impossible to assign a finite probability to
any specific number. 
- If we did, we could do this infinitely and their summed probability would 
surpass 100%. 
- Instead, the density curve is used to determine the probability of an observed 
event within a specific range.

### Density curves

You could use the density curve to calculate:

- $P(CS < 0.20)$
- $P(0.20 < CS < 0.40)$
- $P(CS < 0.2$ or $CS > 0.4) = P(CS < 0.2) + P(CS > 0.4)$ because this events are independent
- $P(CS > 0.4) = 1 - P(CS \leq 0.4)$

- The calculations can be interpreted as either:
    - the **proportion** of hospitals with cesarean delivery rates in the specified 
    range
    - the **probability** that a randomly chosen hospital will have cesarean delivery
    rate in the specified range.

