---
title: "L13:  The Binomial distributions"
---

<!-- libraries -->
```{r,include=FALSE,purl=FALSE}
library(knitr) # for include_graphics() 
library(dplyr)
```


```{r load-libraries, message=F, warning=FALSE, echo=F}
#don't need to worry about knowing these libraries
library(jpeg)
library(grid)
library(tidyverse)
```

### Today's objectives
  - Introduce the binomial distribution
  - What kinds of outcomes follow a binomial
  - Understanding the probability space for a binomial
  - What is the theoretical distribution for binomials 
  - discuss exact vs. cummulative probabilities for the binomial 
  - introduce some R code for binomial distributions

### Other types of outcomes
We've now seen how we can use a normal probability distribution to help us evaluate continuous variables.

What about expected values(probabilities) for all the outcomes that have only 2 possibilities

### The binomial setting and binomial distributions
- An elementary school administers eye exams to 800 students. How many students have perfect vision?
- A new treatment for pancreatic cancer is tried on 250 patients. How many survive for five years?
- You plant 10 dogwood trees. How many live through the winter?

### What are the common threads to each of these questions?

- Something is done $n$ number of times.
- The outcome of interest for each question is categorical (binary - two levels)

## Binomial Distributions


### Binomial Probability Distributions and notation
- Bernoulli Random Variable: The variable must assume one of two possible mutually exclusive outcomes
- Each trial of the BRV results in either a success or failure of the event happening

- Derived from the experiment: counting the number of occurrences of an event in n independent trials
- Random Variable: X = number of times the event happens in the fixed number of trials (n)
- Parameters
  
    - n = number of trials
    - p = probability of success (event happening)
  

### Bernoulli Process
- The $n$ observations are independent. Knowing the result of one observation does not change the probabilities assigned to other observations
- Each observations is either a "success" or a "failure" (usually noted with 0 or 1). These terms are used for convenience.
- The probability of success, call it $p$ is the same for each observation. 

$$P(0\cup 1)= P(0)+P(1)=1$$

### Example 1

A researcher has access to 40 men and 40 women and selects 10 of them at random
to participate in an experiment. The number of women selected can be represented 
by X. Is X binomially distributed?

- Read the question carefully. What is the probability of selecting a woman 
when there are 40 individuals. If a woman is chosen, what is the probability of
selecting a women the second time? 

### Example 2

A pharmaceutical company inspects a simple random sample of 10 empty plastic 
containers from a shipments of 10,000. They are examined for traces of benzene.
Suppose that 10% of the containers in the shipment contain benzene. Let $X$ 
represent the number of containers contaminated with benzene. Is $X$ binomially 
distributed?

- Issue: Each time you sample one bottle, it affects the chance that the next
bottle will be contaminated. However given that the population is size 10,000 
and the sample size is 10, the effect of one sample's success status on the next
bottle's success status is negligible. 

- Here the distribution of $X$ is *approximately* Binomial:
$$X \dot\sim Binom(10000, 0.10)$$
where $\dot\sim$ is read as "approximately distributed as".

### Binomial probability

If $X$ has the binomial distribution with $n$ observations and probability $p$
of success on each observation, the possible values of $X$ are 0, 1, 2, ..., n.
If $k$ is any one of these values,

$$P(X=k)={n\choose k}p^k(1-p)^{n-k}$$

- Read ${n\choose k}$ as "n choose k". It counts the number of ways in which $k$
successes can be arranged among $n$ observations. 
    - The binomial probability is this count multiplied by the probability of any one 
specific arrangement of the $k$ successes.
  
  
## Sampling distribution of binomial  


### Definition: sampling distribution

A **sampling distribution** is shown as the distribution (with a histogram) of a 
**sample statistic** after taking many samples.

The distribution of the number of successes across many samples is called the 
**sampling distribution** for X. with mean # successes denoted by $\bar{x}$

The distribution of the proportion of successes across many samples is called the 
**sampling distribution** for $p$ with mean proportion successes denoted by $\hat{p}$



### Binomial approximation when $N$ is much larger than $n$

Choose a simple random sample of size $n$ from a population with proportion $p$
of successes. When the population size ($N$) is much larger than the sample, the 
count $X$ of successes in the sample has approximately the binomial distribution 
with parameters $n$ and $p$.

## Example Trial of 2

### Smoking status
In 1987, 29% of the adults in the United States smoked cigarettes, cigars, or pipes.

Let Y be a random variable that represents smoking status.

  - Y = 1, an adult is currently a smoker

  - Y = 0, an adult is not a current smoker

The two values of Smoking status are mutually exclusive and exhaustive.

What is the probability a randomly selected person is a smoker? P(Y=1)

What is the probability a randomly selected person is a non-smoker? P(Y=0)


### Smoking status
Suppose that we randomly select two individuals from the population of adults in the United States. 

The random variable X represents the number of persons in the pair who are current smokers.


|First Person($Y_{1}$)|Second Person ($Y_{2}$)|Probability  |Number of Smokers (X)|
|:-------------:|:--------------------------:|:----------:|:---------:|
|0         |0     |        |0         |
|1         |0     |        |1         |
|0         |1     |        |1         |
|1         |1     |        |2         | 




### Smoking status
Suppose that we randomly select two individuals from the population of adults in the United States. 

The random variable X represents the number of persons in the pair who are current smokers.

|First Person($Y_{1}$)|Second Person ($Y_{2}$)|Probability  |Number of Smokers (X)|
|:-------------:|:--------------------------:|:----------:|:---------:|
|0         |0     |$(1-p)\times(1-p)$     |0         |
|1         |0     |$p\times(1-p)$         |1         |
|0         |1     |$(1-p)\times p$         |1         |
|1         |1     |$p\times p)$         |2         | 

Remember that we can multiply to get the probabilities here because the events are independent

### Smoking status
Recall that for one trial,  P(event) + P(no event) = 1 

So P(smoker) + P(not smoker) =1

We know P(smoker) = 29% so :

1 - 0.29 = 0.71 (probability of non smoker)

### Calculate by hand using a table

If 29% of US adults smoked, p=0.29, what are the values of these probabilities?

The random variable X represents the number of persons in the pair who are current smokers.


|First Person($Y_{1}$)|Second Person ($Y_{2}$)|Probability  |Number of Smokers (X)|
|:-------------:|:--------------------------:|:----------:|:---------:|
|0         |0     |$(.71)\times(.71)=.5041$     |0         |
|1         |0     |$.29\times(.71)=.2059$         |1         |
|0         |1     |$(.71)\times .29=.2059$         |1         |
|1         |1     |$.29\times .29)=.0841$         |2         | 

Notice here that the sum of column 3 is = 1 

### Probability distribution for 2 selected individuals
```{r 2ind, echo=FALSE}
graph <- function(n,p){
  x <- dbinom(0:n,size=n,prob=p)
  return(barplot(x,names.arg=0:n,,xlab="Number of Successes",
     ylab="Probability", main="Probability Distribution"))
}

graph(2,0.29)
```


### Binomial Probability Distributions

In the binomial distribution the sum of all probabilities of potential outcomes equals 100% (1.0)

If you have a certain number of events with probability of success (p),

What is probability that X is occurs at least once P(X>=1)?

> P (X >= 1) = 1 â€“ P (X = 0)

If you have a certain number of events with probability of success (p),

what is probability that X occurs fewer than twice P(X<2)?

> P(X < 2) = P (X = 1) + P (X = 0)

### Binomial Probability Distributions: for n trials
What if we are interested in the expected outcomes if select a larger group of individuals?
It starts to get cumbersome to write out that table by hand.
The general expression of the probability distribution of a binomial random variable X where x is the number of successes in a sample of size n.
$$
P(X=x)= {n\choose x}p^x(1-p)^{n-x}
$$

where n = 1,2,3,... and x = 0,1,...n.


### Binomial Combinations: How many combinations of n people give x successes?

$$
{n\choose x}=\frac{n!}{x!(n-x)!}
$$
$$
{2\choose 0}=\frac{2!}{0!(2-0)!} = 1
$$
$$
{2\choose 1}=\frac{2!}{1!(2-1)!} = 2
$$
**remember that 0! = 1


### Binomial Probability Distributions

So for 1 success in 2 individuals (n=2, x=1) where 29% are smokers (p=0.29)

$$
P(X=x)= {n\choose x}p^x(1-p)^{n-x}
$$
$$
P(X=1)= {2\choose 1}0.29^1(1-0.29)^{2-1} = 0.4118
$$

### Binomail Probability Distributions

We can use the formulas as shown to calculate the probability of a given number of successes from a binomial by hand

Or we could use R with 'dbinom(#successes,size,probability of success)'

This function calculates the probability of observing `x` successes when $X \sim Binom(n,p)$

```{r user, echo=TRUE}
dbinom(1,size=2,prob=0.29)
```


let's look further at sampling distributions using our container example...

## Example trial of size 10

### Sampling distribution of a count in R

First, set up a large population of size 10,000 where 10% of the containers are 
contaminated by benzene. We call `benzene` a "success" since it is coded as 1.
We can see that 10% of the containers are contaminated and 1000 bottles are 
"successes"

We simulate these data:
```{r simulate-binomial-population}
container.id <- 1:10000
benzene <- c(rep(0, 9000), rep(1, 1000))
pop_data <- data.frame(container.id, benzene)
```

### Sampling distribution of a count in R

```{r}
# Calculate the population number of bottles contaminated by benzene and the 
# population mean proportion
pop_stats <- pop_data %>% summarize(pop_num_successes = sum(benzene),
                                    pop_mean = mean(benzene))

pop_stats
```

### Sampling distribution of a count in R

Take a sample of size 10 from the population. Note that 10 is much smaller than
10,000. 

- How many contaminated bottles are we expecting in the sample?
- Given that we sample 10, what is the full range of possible values we could 
see for X, the number of successes and $p$ the proportion of successes? 
- Which values are most likely?

```{r}
# first sample
set.seed(1)
sample_data <- pop_data %>% sample_n(10)
sample_data %>% summarize(sample_num_successes = sum(benzene),
                          sample_mean = mean(benzene))
```

### Sampling distribution of a count in R

We only took one sample, and got 2 successes for a sample mean of 20%. Is that 
usual or unusual? 

To see what is most likely, we need to imagine repeatedly taking samples of 
size 10 from the population and calculating the sample number of successes and 
proportion of successes for each sample.


For the next few slides, we focus on the sampling distribution for X.

### Sampling distribution of a count in R

The embedded code takes 1000 samples each of size 10. 

It then calculates the mean sample proportion and number of successes for each sample and stores all the results in a data frame. 

You don't need to know how the code works.

```{r take-many-samples, echo=FALSE}
# students, you don't need to understand the new parts of this code (i.e., how
# to write a function, or use `replicate`, `lapply`, or `bind_rows`)

calc_sample_stats <- function(df) {
  df %>% 
    summarize(sample_proportion = mean(benzene),
              sample_num_successes = sum(benzene))
}

many.sample.stats <- replicate(1000, sample_n(pop_data, 10), simplify = F) %>%
  lapply(., calc_sample_stats) %>%
  bind_rows() %>%
  mutate(sample.id = 1:n())
```

### Sampling distribution of a count in R

Here are the first rows of the data frame we made on the previous slide.
Each row represents an independent sample from the population. 

```{r show-many-samples}
head(many.sample.stats)
```

### Sampling distribution of a count in R

We want to know: Of the 1000 samples, what percent observed 0 contaminated 
bottles? What percent observed 1 contaminated bottle? And so on. We can used 
`dplyr` functions to calculate this and plot the results in a histogram.

```{r histogram-sampling-distribution, warning=F}
aggregated.stats <- many.sample.stats %>% 
  group_by(sample_num_successes) %>% 
  summarize(percent = n()/1000)
```

### Sampling distribution of a count in R
```{r hist-sample, warning=F}
aggregated.stats
```

### Sampling distribution of a count in R

```{r, fig.align='center', out.width="80%", warning=F, echo = F}
# note: We want a histogram, but R is interpreting these data as a bar chart
# this is, we don't want space between the bars because the x variable is quantitative. 

ggplot(aggregated.stats, aes(x = as.numeric(sample_num_successes), y = percent)) + 
  geom_histogram(col = "grey", stat = "identity") +
  theme_minimal(base_size = 15) + 
  labs(title = "Histogram of the number of \nsuccesses observed across 1000 samples",
       x = "Number of contaminated bottles", y = "percent in each bin") +
  scale_x_continuous(labels = 0:5, breaks = 0:5)
```

### Sampling distribution of a count in R

As we will see in a moment, this histogram *approximates* the shape of the 
binomial distribution with n = 10 and p = 0.1. Observing one success is the most
likely outcome. Why is that?

### Worked probabilities, x = 0

We sampled n=10 bottles where the probability of success on any one pick is 10%.

- What is the chance of observing zero contaminated bottles?
- This means the first bottle is not contaminated and the second bottle is 
    not contaminated, and ... and the tenth bottle is not contaminated
    
$P(X_1=0 \text{ and } X2=0 \text{ and...and } X_{10}=0 )$

= $P(X_1=0)\times P(X_2=0) \times ... \times P(X_{10}=0)$ , using the multiplication rule for independent events

= $(0.90)^{10}$

= $0.3486784 = 34.9\%$

### Worked probabilities, x = 1

- What is the chance of observing exactly one contaminated bottle?
- Suppose that the first bottle was contaminated, then all the rest had to be 
not contaminated. What is the probability of observing this specific sequence
of events?

$P(X_1=1 \text{ and } X2=0 \text{ and } X3=0 \text{ and...and } X_{10}=0 )$

= $P(X_1=1)\times P(X_2=0) \times P(X_3=0)... \times P(X_{10}=0)$

= $(0.1)^1(0.90)^{9}$

= $0.03874205 = 3.87\%$

But we're not done. This is only one specific way of observing exactly one 
contaminated bottle. What is another way? How many ways are there to observed 
exactly one contaminated bottle when there are ten bottles?

### Worked probabilities, x = 1
There are ten ways to observe exactly one contaminated bottle:

* 1, 0, 0, 0, 0, 0, 0, 0, 0, 0
* 0, 1, 0, 0, 0, 0, 0, 0, 0, 0
* 0, 0, 1, 0, 0, 0, 0, 0, 0, 0
* 0, 0, 0, 1, 0, 0, 0, 0, 0, 0
* 0, 0, 0, 0, 1, 0, 0, 0, 0, 0
* ...
* 0, 0, 0, 0, 0, 0, 0, 0, 0, 1



### Worked probabilities, x = 1
Remember 
$$
{n\choose x}=\frac{n!}{x!(n-x)!}
$$
$$
{10\choose 1}=\frac{10!}{1!(10-1)!} = 10
$$


### Worked probabilities, x = 1
Each of these ten ways has the same probability of occurring.

$P(\text{observed exactly 1 contaminated bottle})$ =

$P(\text{{1st bottle is contaminated, and rest are not} OR {2nd bottle is contaminated, and rest are not} OR... OR {10th bottle is contaminated and the rest are not}})$

$= (0.1)^1(0.9)^{9} + (0.1)^1(0.9)^{9} + ... + (0.1)^1(0.9)^{9}$, using the addition rule for disjoint events

$= 10 \times (0.1)^1(0.9)^{9}$

$= 0.3874205 = 38.7\%$

### Worked probabilities, x = 1

We can check our calculations using the `dbinom()` function in R. 

```{r}
dbinom(x = 1, size = 10, prob = 0.1)
```

This is exactly the answer we obtained.

### Worked probabilities, x = 2

What is chance of observing exactly two contaminated bottles?

Following the same line of thinking, suppose that the first two bottles were
contaminated. The chance of this happening is:

$(0.1)^2(0.9)^8 = 0.004303672$

But how many ways are there to observe exactly two contaminated bottles? 


### Worked probabilities, x = 2
Remember 
$$
{n\choose x}=\frac{n!}{x!(n-x)!}
$$
$$
{10\choose 2}=\frac{10!}{2!(10-2)!} = 45
$$

You could write out all the possibilities like last time, but there are a lot more! 

### Worked probabilities, x = 2
Note: we can get our calculators or R to perform this calculation for us. On our calculator, 
we need the button ${n \choose k}$, pronounced "n choose k", and asks how many ways
are there to have $k$ successes when there are $n$ individuals? In R we need the 
function `choose(n, k)`

```{r 10-choose-2}
choose(10, 2)
```

There are 45 ways to observe exactly two contaminated bottles when you 
have ten bottles observed.

**Make sure you can also perform this calculation on your calculator!**

### Worked probabilities, x = 2

To get the probability of observing exactly 2 contaminated bottles, because all of the possible combinations are equally possible, we can multiply 45 by the probability of observing the first two bottles as being contaminated:

$45 \times (0.1)^2(0.9)^8 = 0.1937102 = 19.4\%$

Check using R:

```{r}
#fill in during class
```


### All of the combinations with 10 bottles 
Each of these is written as ${10 \choose k}$, where k is 0, 1, 2, ..., 10. This is
known as the **binomial coefficient**.

Let's compute `choose(n, k)`, for n=10, and k=0, 1, 2, ..., 10:
```{r 10-choose-k, echo=F}
choices<- cbind(choose(10, 0),
choose(10, 1),
choose(10, 2),
choose(10, 3),
choose(10, 4),
choose(10, 5),
choose(10, 6),
choose(10, 7),
choose(10, 8),
choose(10, 9),
choose(10, 10))
choices
#might be interesting to link this to Pascal's triangle.
```

Notice the symmetric structure of `choose(n, k)`. Why is it symmetric? 

### Binomial probability

Recal from lecture 15:

If $X$ has the binomial distribution with $n$ observations and probability $p$
of success on each observation, the possible values of $X$ are 0, 1, 2, ..., n.
If $k$ is any one of these values,

$$P(X=k)={n\choose k}p^k(1-p)^{n-k}$$

## Binomial probability in R

### Binomial probability in R using `dbinom()` 

- Recall for Normal distributions we used `pnorm()` to calculate the probability
**below** a given number.
- For discrete distributions we can calculate the probability of observing a 
specific value. For example, we can ask: What is the probability that exactly
3 of the ten bottles were contaminated when the risk of contamination was 10%?

- `dbinom()` is used to compute *exactly* 3

```{r}
dbinom(x = 3, size = 10, prob = 0.1)
```

### Binomial probability in R using  `pbinom()`

- Recall for Normal distributions we used `pnorm()` to calculate the probability
**below** a given number.

- For our Binomial, we can also ask, what is the probability that 3 or less of the ten bottles were
contaminated when the risk of contamination was 10%?
-  `pbinom()` is used to compute 3 *or less*

```{r}
dbinom(x = 3, size = 10, prob = 0.1)
pbinom(q = 3, size = 10, prob = 0.1)
```


### Histogram of binomial probabilities

This histogram shows the probability of observing each value of $X$. That is, it
shows the $P(X =x)$, for $x$ in 0,1,2, ... 10, when $X \sim Binom(n=10, p = 0.1)$

```{r, out.width="80%", fig.align='center', echo=F, warning=F}
#students, don't worry about this code
point.probs <- rep(NA, 11)

for(i in 1:11) {
  point.probs[i] <- dbinom(x = i-1, size = 10, prob = 0.1)
}

ggplot(data.frame(point.probs), aes(x = 0:10, y = point.probs)) +
  geom_histogram(stat = "identity", binwidth = 1) +
  labs(y = "Probability",
       x = "Number of successes") +
  theme_minimal(base_size = 15) +
  scale_x_continuous(breaks = c(0, 2, 4, 6, 8, 10))

```

### Exact discrete probability, graphed

```{r, fig.align='center', out.width="80%", echo=F, warning=F}
ggplot(data.frame(point.probs), aes(x = 0:10, y = point.probs)) +
  geom_histogram(stat = "identity", binwidth = 1, aes(fill = as.factor(round(point.probs, 2) == 0.06 ))) +
  labs(y = "Probability",
       x = "Number of successes") +
  theme_minimal(base_size = 15) +
  scale_x_continuous(breaks = c(0, 2, 4, 6, 8, 10)) + 
  scale_fill_discrete(labels = c("other", "P(X=3)"), breaks = c(FALSE, TRUE), name = "")
```

```{r exact-prob}
dbinom(x = 3, size = 10, prob = 0.1)
```


### Cumulative discrete probability, graphed

```{r, fig.align='center', out.width="80%", warning=F, echo=F}
ggplot(data.frame(point.probs), aes(x = 0:10, y = point.probs)) +
  geom_histogram(stat = "identity", binwidth = 1, aes(fill = as.factor(round(point.probs, 2) >= 0.06 ))) +
  labs(y = "Probability",
       x = "Number of successes") +
  theme_minimal(base_size = 15) +
  scale_x_continuous(breaks = c(0, 2, 4, 6, 8, 10)) + 
  scale_fill_discrete(labels = c("other", "P(X<=3)"), breaks = c(FALSE, TRUE), name = "")
```

```{r}
pbinom(q = 3, size = 10, prob = 0.1)
```



## Mean and Variance of a Binomial
    
### Binomial mean and standard deviation

If a count $X$ has the binomial distribution with $n$ number of observations and 
$p$ as the probability of success, then the population mean and population 
standard deviation are:

$$\mu = np$$

$$\sigma = \sqrt{np(1-p)}$$


### Example of mean and SD calculations

Recall our example of the number of bottles contaminated in benzene, where 
$X \sim Binom(n = 10,p = 0.1)$. 

$\mu = np = 10 \times 0.1 = 1$

$\sigma = \sqrt{np(1-p)} = \sqrt{10\times 0.1(1-0.1)} = 0.9487$

Thus, we **expect** to find one container contaminated with benzene per sample,
on average. The standard deviation can be thought of, very roughly, as the
expected deviation from this mean if you were to take many random samples.


## Normal approximation of a binomial

### Histogram of binomial probabilities with different values for p

Here we have n = 10, and p = 0.10 (green), 0.5 (pink), and 0.8 (blue)

```{r, out.width="80%", fig.align='center', echo=F, warning=F}
#students, don't worry about this code
point.probs <- rep(NA, 11)
point.probs2 <- rep(NA, 11)
point.probs3 <- rep(NA, 11)

for(i in 1:11) {
  point.probs[i] <- dbinom(x = i-1, size = 10, prob = 0.5)
  point.probs2[i] <- dbinom(x = i-1, size = 10, prob = 0.10)
  point.probs3[i] <- dbinom(x = i-1, size = 10, prob = 0.80)
}

probs <- data.frame(point.probs, point.probs2, point.probs3)

plot1 <- ggplot(probs, aes(x = 0:10, y = point.probs)) +
  geom_histogram(stat = "identity", binwidth = 1, fill = "pink", alpha = 0.5, col = "black") +
  labs(y = "Probability",
       x = "Number of successes") +
  theme_minimal(base_size = 15) +
  scale_y_continuous(limits = c(0, 0.4)) +
  scale_x_continuous(breaks = c(0, 2, 4, 6, 8, 10))

plot2 <- ggplot(probs, aes(x = 0:10, y = point.probs2)) +
  geom_histogram(stat = "identity", binwidth = 1, fill = "green", alpha = 0.5, col = "black") +
  labs(y = "Probability",
       x = "Number of successes") +
  theme_minimal(base_size = 15) +
  scale_y_continuous(limits = c(0, 0.4)) +
  scale_x_continuous(breaks = c(0, 2, 4, 6, 8, 10))

plot3 <- ggplot(probs, aes(x = 0:10, y = point.probs3)) +
  geom_histogram(stat = "identity", binwidth = 1, fill = "blue", alpha = 0.5, col = "black") +
  labs(y = "Probability",
       x = "Number of successes") +
  theme_minimal(base_size = 15) +
  scale_y_continuous(limits = c(0, 0.4)) + 
  scale_x_continuous(breaks = c(0, 2, 4, 6, 8, 10))


library(patchwork)

plot2 + plot1 + plot3 + plot_layout(ncol = 3)
```


### Histogram of binomial probabilities with different values for p

How does the shape change when the probability is closer to .5?

What do you think happens when n gets larger?

### An approximation to the binomial distribution when n is large

Imagine a setting where $X \sim Binom(n = 2000, p = 0.62)$. Then:

$$P(X=k)={2000\choose k}0.62^k(1-0.62)^{2000-k}$$
And:

$$P(X \leq k)=\sum_{i=0}^k {2000\choose i}0.62^k(1-0.62)^{2000-k}$$

If you were asked to calculate this by hand for, say, k = 100, it would take a 
very long time.

### An approximation to the binomial distribution when n is large

Consider the probability distribution for $P(X=k)={2000\choose k}0.62^k(1-0.62)^{2000-k}$

What shape does this remind you of?

```{r calculate-prob-distn-binom, echo = F, fig.align='center', out.width="80%", warning=F}
#students, don't worry about this code
point.probs.2k <- rep(NA, 2001)

for(i in 1:2001) {
  point.probs.2k[i] <- dbinom(x = i-1, size = 2000, prob = 0.62)
}

zoomed.out <- ggplot(data.frame(point.probs.2k), aes(x = 0:2000, y = point.probs.2k)) +
  geom_histogram(stat = "identity", binwidth = 1) +
  labs(y = "Probability",
       x = "Number of successes") +
  theme_minimal(base_size = 15) 

zoomed.in <- ggplot(data.frame(point.probs.2k), aes(x = 0:2000, y = point.probs.2k)) +
  geom_histogram(stat = "identity", binwidth = 1, col = "white") +
  labs(y = "Probability",
       x = "Number of successes") +
  theme_minimal(base_size = 15) +
  scale_x_continuous(limits = c(1150, 1350))

#zoomed.out + zoomed.in + plot_layout(ncol = 2)

zoomed.in
```

### An approximation to the binomial distribution when n is large

The previous graph is unimodal and symmetric. Let's calculate $\mu$ and $\sigma$:

$\mu = np = 2000 \times 0.62 = 1240$

$\sigma = \sqrt{np(1-p)} = \sqrt{2000 \times 0.62 \times (1-0.62)} = 21.70714$

### How much data is within 1 SD of the mean?

1240 +/- 1 SD gives the range {1218.293, 1261.707}

Thus, we can use R to add up all the probabilities between X = 1218 and X = 1262
to give an approximate guess to the area 1 SD from the mean:

This code cycles through the probabilities to add them up

```{r}
#students, no need to know how to write this code.
cumulative.prob <- 0
 
for(i in 1218:1262){
  cumulative.prob <- cumulative.prob + point.probs.2k[i]
}

cumulative.prob
```

### How much data is within 2 SD of the mean?

1240 +/- 2 SD gives the range {1196.586, 1283.414}

Thus, we can use R to add up all the probabilities between X = 1197 and X = 1283
to give an approximate guess to the area 1 SD from the mean:

This code cycles through the probabilities to add them up

```{r}
#students, no need to know how to write this code.
cumulative.prob.2 <- 0
 
for(i in 1197:1283){
  cumulative.prob.2 <- cumulative.prob.2 + point.probs.2k[i]
}

cumulative.prob.2
```
- You could also perform the check for 3 SD

### The Normal approximation to Binomial distributions

From the previous calculations, you might see that the shape looks 
Normal and that the distribution nearly meets the 68%-95%-99.7% rule. Thus, it is
approximately Normal.

This means that you can use the Normal distribution to perform calculations when
data is binomially distributed with large n.

### Example calculation of the Normal approximation to the Binomial 

Suppose we want to calculate $P(X \geq 1250)$ using the Normal approximation.

```{r}
# write the Normal code
1- pnorm(q = 1250, mean = 1240 , sd = 21.70714)
```

Check how well the approximation worked: 

```{r}
# write the binomial code and see how well the approximation is
1 - pbinom(q = 1249, size = 2000, prob = 0.62)
```

### Normal approximation for binomial distributions

Suppose that a count X has the binomial distribution with $n$ observations and 
success probability $p$. When $n$ is large, the distribution of $X$ is 
approximately Normal. That is, 

$$X \dot\sim N(\mu = np, \sigma = \sqrt{np(1-p)})$$

As a general rule, we will use the Normal approximation when $n$ is so large
that $np \geq 10$ and $n(1-p) \geq 10$.

It is most accurate for $p$ close to 0.5, and least accurate for $p$ closer to 0 
or 1.

### Normal approximation with continuity correction

This approximation can be improved a tiny bit! 

As you know, counts can only take integer values, but continuous data can take 
any real value. The proper continuous equivalent to a count is the interval 
around the count with size 1. For example, the continuous equivalent to a 1250 
count is the interval between 1249.5 and 1250.5. Thus, we should compute 
P(X >= 1249.5) rather than P(X > 1250) for an even more accurate answer.

This correction makes a bigger difference when $n$ is small.

```{r normal-approx-with-cont-corr}
1- pnorm(q = 1249.5, mean = 1240 , sd = 21.70714)
```

## Linking to Pascal's triangle (Bonus material)

### An aside:  Pascal's triangle
$${0\choose 0}$$
$${1\choose 0} {1\choose 1}$$
$${2\choose 0} {2\choose 1}{2\choose 2}$$
$${3\choose 0} {3\choose 1}{3\choose 2}{3\choose 3}$$

### An aside:  Pascal's triangle
$$1$$
$$1  1$$
$$1  2  1$$
$$1  3  3  1$$

TED ed Video about Pascal's triangle https://www.youtube.com/watch?v=XMriWTvPXHI
